{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'logistic_regression'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "selected_features = select_features(X, y, LogisticRegression(max_iter=10000), 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "logistic_regression = LogisticRegression(max_iter=10000)\n",
    "grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'svm'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "selected_features = select_features(X, y, SVC(kernel='linear'), 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "svm = SVC(probability=True)\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'knn'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "selected_features = select_features(X, y, logistic_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'naive_bayes'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "selected_features = select_features(X, y, logistic_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0, -9, num=100)\n",
    "}\n",
    "naive_bayes = GaussianNB()\n",
    "grid_search = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'lda'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "selected_features = select_features(X, y, LinearDiscriminantAnalysis(), 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': [None, 'auto'] + list(np.linspace(0, 1, 20))\n",
    "}\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'qda'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "selected_features = select_features(X, y, logistic_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'reg_param': np.linspace(0, 1, 20)\n",
    "}\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "grid_search = GridSearchCV(estimator=qda, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.predict_proba(X_selected)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.predict_proba(X_subset)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.predict_proba(X_external)[:, 1]\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'kmeans'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "selected_features = select_features(X, y, logistic_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_clusters': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'n_init': [10, 20, 30],\n",
    "    'max_iter': [300, 600, 900]\n",
    "}\n",
    "kmeans = KMeans()\n",
    "grid_search = GridSearchCV(estimator=kmeans, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = best_model.predict(X_selected)\n",
    "y_prob = best_model.transform(X_selected).min(axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "auc = roc_auc_score(y, y_prob)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = best_model.predict(X_subset)\n",
    "    y_prob_subset = best_model.transform(X_subset).min(axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_subset)\n",
    "    precision = precision_score(y_subset, y_pred_subset)\n",
    "    recall = recall_score(y_subset, y_pred_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_subset)\n",
    "    auc = roc_auc_score(y_subset, y_prob_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_prob_external = best_model.transform(X_external).min(axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_external)\n",
    "    precision = precision_score(y_external, y_pred_external)\n",
    "    recall = recall_score(y_external, y_pred_external)\n",
    "    f1 = f1_score(y_external, y_pred_external)\n",
    "    auc = roc_auc_score(y_external, y_prob_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'linear_regression'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "selected_features = select_features(X, y, linear_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'copy_X': [True, False]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=linear_model, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(best_model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'ridge_regression'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "ridge_model = Ridge()\n",
    "selected_features = select_features(X, y, ridge_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=ridge_model, param_grid=param_grid, cv=10, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search.fit(X_selected, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_features_list = selected_features.tolist()\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(best_features_list, columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + best_features_list]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, best_features_list, best_model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[best_features_list]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(best_model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, best_features_list, best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, best_features_list, best_model, model_name):\n",
    "    X_external = external_data[best_features_list]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = best_model.predict(X_external)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, best_features_list, best_model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, best_features_list, best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, best_features_list, best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'mlp_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    selector = RFE(estimator=model, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "selected_features = select_features(X, y, logistic_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "grid_search = GridSearchCV(estimator=mlp_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'decision_tree_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "selected_features = select_features(X, y, decision_tree_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=decision_tree_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'random_forest_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "random_forest_model = RandomForestClassifier()\n",
    "selected_features = select_features(X, y, random_forest_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'gradient_boosting_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "gradient_boosting_model = GradientBoostingClassifier()\n",
    "selected_features = select_features(X, y, gradient_boosting_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gradient_boosting_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'adaboost_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost_model = AdaBoostClassifier(estimator=base_estimator)\n",
    "selected_features = select_features(X, y, adaboost_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "    'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'xgboost_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "xgboost_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "selected_features = select_features(X, y, xgboost_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'lightgbm_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "lightgbm_model = lgb.LGBMClassifier()\n",
    "selected_features = select_features(X, y, lightgbm_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "    'min_child_samples': [20, 30, 50],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lightgbm_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'catboost_classifier'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "catboost_model = CatBoostClassifier(verbose=0)\n",
    "selected_features = select_features(X, y, catboost_model, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5],\n",
    "    'border_count': [32, 64, 128]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LassoCV, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'lasso_regression'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "lasso = LassoCV(cv=10)\n",
    "selected_features = select_features(X, y, lasso, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=logistic, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNetCV, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "model_name = 'elastic_net'\n",
    "\n",
    "data = pd.read_csv('..')\n",
    "external_data1 = pd.read_csv('..')\n",
    "external_data2 = pd.read_csv('..')\n",
    "\n",
    "X = data.drop(columns=['NID', 'time1', 'IIR_3revi'])\n",
    "y = data['IIR_3revi']\n",
    "\n",
    "def select_features(X, y, model, n_features):\n",
    "    model.fit(X, y)\n",
    "    selector = SelectFromModel(model, max_features=n_features, prefit=True)\n",
    "    return X.columns[selector.get_support(indices=True)]\n",
    "\n",
    "elastic_net = ElasticNetCV(cv=10)\n",
    "selected_features = select_features(X, y, elastic_net, 8)\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['elasticnet'],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 0.9]\n",
    "}\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=logistic, param_grid=param_grid, cv=10, n_jobs=8)\n",
    "grid_search.fit(X_selected, y)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "pd.DataFrame([best_params]).to_csv(f'{model_name}_best_params.csv', index=False)\n",
    "pd.DataFrame(list(selected_features), columns=['Best Features']).to_csv(f'{model_name}_best_features.csv', index=False)\n",
    "\n",
    "best_model_data = data[['NID', 'time1', 'IIR_3revi'] + list(selected_features)]\n",
    "best_model_data.to_csv(f'{model_name}_best_model_data.csv', index=False)\n",
    "\n",
    "y_pred = cross_val_predict(best_model, X_selected, y, cv=10)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred_binary)\n",
    "precision = precision_score(y, y_pred_binary)\n",
    "recall = recall_score(y, y_pred_binary)\n",
    "f1 = f1_score(y, y_pred_binary)\n",
    "auc = roc_auc_score(y, y_pred)\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_pred_binary).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = recall\n",
    "\n",
    "overall_metrics = {\n",
    "    'Accuracy': accuracy,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1,\n",
    "    'AUC': auc,\n",
    "    'Specificity': specificity,\n",
    "    'Sensitivity': sensitivity\n",
    "}\n",
    "pd.DataFrame([overall_metrics]).to_csv(f'{model_name}_overall_metrics.csv', index=False)\n",
    "\n",
    "def calculate_metrics_at_time(time_point, data, selected_features, model):\n",
    "    subset = data[data['time1'] > time_point]\n",
    "    X_subset = subset[selected_features]\n",
    "    y_subset = subset['IIR_3revi']\n",
    "    \n",
    "    y_pred_subset = cross_val_predict(model, X_subset, y_subset, cv=10)\n",
    "    y_pred_binary_subset = (y_pred_subset > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_subset, y_pred_binary_subset)\n",
    "    precision = precision_score(y_subset, y_pred_binary_subset)\n",
    "    recall = recall_score(y_subset, y_pred_binary_subset)\n",
    "    f1 = f1_score(y_subset, y_pred_binary_subset)\n",
    "    auc = roc_auc_score(y_subset, y_pred_subset)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_subset, y_pred_binary_subset).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    return {\n",
    "        'Time Point': time_point,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "\n",
    "time_points = [5, 6, 7]\n",
    "metrics_at_times = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, data, list(selected_features), best_model) for tp in time_points)\n",
    "pd.DataFrame(metrics_at_times).to_csv(f'{model_name}_metrics_at_times.csv', index=False)\n",
    "\n",
    "def evaluate_external_data(external_data, selected_features, model, model_name):\n",
    "    X_external = external_data[selected_features]\n",
    "    y_external = external_data['IIR_3revi']\n",
    "    \n",
    "    y_pred_external = cross_val_predict(model, X_external, y_external, cv=10)\n",
    "    y_pred_binary_external = (y_pred_external > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_external, y_pred_binary_external)\n",
    "    precision = precision_score(y_external, y_pred_binary_external)\n",
    "    recall = recall_score(y_external, y_pred_binary_external)\n",
    "    f1 = f1_score(y_external, y_pred_binary_external)\n",
    "    auc = roc_auc_score(y_external, y_pred_external)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_external, y_pred_binary_external).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = recall\n",
    "    \n",
    "    overall_metrics_external = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'AUC': auc,\n",
    "        'Specificity': specificity,\n",
    "        'Sensitivity': sensitivity\n",
    "    }\n",
    "    pd.DataFrame([overall_metrics_external]).to_csv(f'{model_name}_external_overall_metrics.csv', index=False)\n",
    "    \n",
    "    metrics_at_times_external = Parallel(n_jobs=8)(delayed(calculate_metrics_at_time)(tp, external_data, list(selected_features), model) for tp in time_points)\n",
    "    pd.DataFrame(metrics_at_times_external).to_csv(f'{model_name}_external_metrics_at_times.csv', index=False)\n",
    "\n",
    "evaluate_external_data(external_data1, list(selected_features), best_model, f'{model_name}_ditan')\n",
    "evaluate_external_data(external_data2, list(selected_features), best_model, f'{model_name}_youan')\n",
    "\n",
    "joblib.dump(best_model, f'{model_name}_best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To alter the designated feature, use the following code for all algorithms:\n",
    "selected_features = ['B9', 'B8', 'B12_group', 'B18_group', 'B10_group', 'AGE_10', 'B16_group', 'B2', \n",
    "                     'B25', 'B19_group']\n",
    "X = data[selected_features]\n",
    "y = data['IIR_3revi']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lf_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
